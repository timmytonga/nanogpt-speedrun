{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F\n",
    "from train_gpt import GPT\n",
    "\n",
    "@dataclass\n",
    "class Hyperparameters:\n",
    "    # data\n",
    "    train_files: str = \"data/fineweb10B/fineweb_train_*.bin\" # input .bin to train on\n",
    "    val_files: str = \"data/fineweb10B/fineweb_val_*.bin\" # input .bin to eval validation loss on\n",
    "    val_tokens: int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons\n",
    "    train_seq_len: int = 48*1024 # FlexAttention sequence length\n",
    "    val_seq_len: int = 4*64*1024 # FlexAttention sequence length for validation\n",
    "    # optimization\n",
    "    num_iterations: int = 1770 # number of iterations to run\n",
    "    cooldown_frac: float = 0.4 # fraction of training spent cooling down the learning rate\n",
    "    # architecture\n",
    "    vocab_size: int = 50257\n",
    "    # evaluation and logging\n",
    "    val_loss_every: int = 125 # every how many steps to evaluate val loss? 0 for only at the end\n",
    "    save_checkpoint: bool = False\n",
    "    wandb: bool = False\n",
    "    # optimizer setup\n",
    "    lr: float = 0.05  # this is the default for muon\n",
    "    opt1: str = \"adam\"  # choices = ['adam', 'adamw_sn']\n",
    "    optimizer: str = \"muon\"  # choices = ['muon', 'adamw_sn', 'adamw_snsm']\n",
    "    beta1: float = 0.9  # momentum \n",
    "    beta2: float = 0.95  \n",
    "    use_momentum_sched: bool = False \n",
    "    muon_momentum_warmup: bool = True     \n",
    "    single_gpu: bool = True\n",
    "    # scheduler\n",
    "    scheduler: str = \"default\"  # choices: ['linear', 'default']. default is \"constant then decay\".\n",
    "    warmup: int = 0  # specify the number of warmup steps\n",
    "    final_rate: float = 0.1  # final lr decay fraction\n",
    "    # adamw_snsm args\n",
    "    rank: int = 256\n",
    "    update_proj_gap: int = 200\n",
    "    \n",
    "    \n",
    "\n",
    "args = Hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing model\n",
      "Constructing optimizers\n"
     ]
    }
   ],
   "source": [
    "print(\"Constructing model\")\n",
    "model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,\n",
    "        max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Embedding):\n",
    "        m.bfloat16()\n",
    "\n",
    "print(\"Constructing optimizers\")\n",
    "# collect the parameters to optimize\n",
    "hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and \"embed\" not in n]\n",
    "embed_params = [p for n, p in model.named_parameters() if \"embed\" in n]\n",
    "scalar_params = [p for p in model.parameters() if p.ndim < 2]\n",
    "head_params = [model.lm_head.weight]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t0.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t0.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t0.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "1.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t1.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t1.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t1.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "2.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t2.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t2.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t2.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "3.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t3.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t3.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t3.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "4.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t4.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t4.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t4.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "5.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t5.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t5.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t5.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "6.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t6.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t6.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t6.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "\t7.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t7.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "8.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t8.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t8.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t8.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "9.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t9.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t9.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t9.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "10.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t10.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t10.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t10.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n",
      "11.attn.qkv_w: shape = torch.Size([3, 768, 768])\n",
      "\t11.attn.c_proj.weight: shape = torch.Size([768, 768])\n",
      "\t11.mlp.c_fc.weight: shape = torch.Size([3072, 768])\n",
      "\t11.mlp.c_proj.weight: shape = torch.Size([768, 3072])\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.blocks.named_parameters():\n",
    "    if p.ndim == 2:\n",
    "        print(f\"\\t{n}: shape = {p.shape}\")\n",
    "    if p.ndim > 2:\n",
    "        print(f\"{n}: shape = {p.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speedrun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
